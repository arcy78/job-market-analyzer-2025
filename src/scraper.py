import requests
from bs4 import BeautifulSoup
import pandas as pd
import os
from datetime import datetime

# --- CONFIGURATION ---
URL = "https://realpython.github.io/fake-jobs/"
OUTPUT_PATH = "data/raw/jobs_data.csv"

def scrape_jobs():
    """
    Fonction principale pour r√©cup√©rer les donn√©es,
    les nettoyer sommairement et les sauvegarder.
    """
    print(f"üöÄ D√©marrage du scraping sur : {URL}")
    
    # 1. REQU√äTE HTTP (R√©cup√©ration du code HTML)
    try:
        response = requests.get(URL)
        response.raise_for_status() # V√©rifie si la requ√™te a r√©ussi (Code 200)
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Erreur lors de la requ√™te : {e}")
        return

    # 2. PARSING (Analyse du HTML)
    soup = BeautifulSoup(response.content, "html.parser")
    results = soup.find(id="ResultsContainer")
    job_elements = results.find_all("div", class_="card-content")

    print(f"‚ÑπÔ∏è  {len(job_elements)} offres trouv√©es. Extraction en cours...")

    # Liste pour stocker les donn√©es
    jobs_list = []

    # 3. EXTRACTION DES DONN√âES (Boucle sur chaque offre)
    for job in job_elements:
        title = job.find("h2", class_="title").text.strip()
        company = job.find("h3", class_="company").text.strip()
        location = job.find("p", class_="location").text.strip()
        date_posted = job.find("time").text.strip() if job.find("time") else datetime.now().strftime("%Y-%m-%d")

        # Ajout dans notre liste
        jobs_list.append({
            "title": title,
            "company": company,
            "location": location,
            "date_collected": date_posted
        })

    # 4. SAUVEGARDE (Dataframe -> CSV)
    # On cr√©e le dossier s'il n'existe pas
    os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
    
    df = pd.DataFrame(jobs_list)
    df.to_csv(OUTPUT_PATH, index=False)
    
    print(f"‚úÖ Succ√®s ! Les donn√©es ont √©t√© sauvegard√©es dans : {OUTPUT_PATH}")
    print(f"üìä Aper√ßu des 5 premi√®res lignes :\n")
    print(df.head())

if __name__ == "__main__":
    scrape_jobs()